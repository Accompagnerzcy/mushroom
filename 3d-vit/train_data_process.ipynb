{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import scipy.io as scio\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import setting\n",
    "from random import shuffle\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./sample/Train_1_5\n"
     ]
    }
   ],
   "source": [
    "NO='5'\n",
    "\n",
    "data_file =NO  # File name of the data set\n",
    "data_name = 'X'  # Matrix name of the data set within the data file\n",
    "label_file='Label_'+NO\n",
    "no=setting.no\n",
    "train_data_name='./sample/Train_'+str(no)+'_'+NO\n",
    "print(train_data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_data(height_index, width_index):\n",
    "    height_slice = slice(height_index, height_index + PATCH_SIZE)\n",
    "    width_slice = slice(width_index, width_index + PATCH_SIZE)\n",
    "    patches = data_norm[height_slice, width_slice,:]\n",
    "    return np.array(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 204)\n",
      "(512, 512)\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "# input_mat = scio.loadmat(os.path.join(setting.train_data_path, data_file + '.mat'))[data_name]\n",
    "input_mat = h5py.File(os.path.join(setting.train_data_path, data_file + '.mat')) [data_name]\n",
    "input_mat=np.array(input_mat).transpose(2,1,0)\n",
    "label_map = cv2.imread(os.path.join(setting.train_label_path, label_file + '.png'), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "print(input_mat.shape)\n",
    "print(label_map.shape)\n",
    "print(np.unique(label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEIGHT= 512 WIDTH= 512 BAND= 204\n",
      "PATCH_SIZE= 5\n",
      "PATCH_IDX= 2\n",
      "CLASS_NUM= 3\n",
      "DTYPE: float64\n"
     ]
    }
   ],
   "source": [
    "#打印参数 \n",
    "[HEIGHT, WIDTH, BAND] = input_mat.shape\n",
    "print('HEIGHT=',HEIGHT, 'WIDTH=',WIDTH, 'BAND=',BAND)\n",
    "PATCH_SIZE = setting.PATCH_SIZE\n",
    "print('PATCH_SIZE=',PATCH_SIZE)\n",
    "PATCH_IDX = int((PATCH_SIZE - 1) / 2)\n",
    "print('PATCH_IDX=', PATCH_IDX)\n",
    "CLASS_NUM = setting.CLASS_NUM\n",
    "print('CLASS_NUM=',CLASS_NUM)\n",
    "DTYPE=setting.DTYPE\n",
    "print('DTYPE:', DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 204)\n",
      "max: 0.9696969985961914 \n",
      "min: 0.04678770899772644\n"
     ]
    }
   ],
   "source": [
    "data_norm=input_mat.astype(DTYPE)\n",
    "print(data_norm.shape)\n",
    "print('max:',np.max(data_norm),'\\nmin:',np.min(data_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS 0\t 0\n",
      "CLASS 1\t 29779\n",
      "CLASS 2\t 7590\n"
     ]
    }
   ],
   "source": [
    "# 按类别归整样本\n",
    "CLASSES = []\n",
    "POSITION=[]\n",
    "for i in range(CLASS_NUM):\n",
    "    CLASSES.append([])\n",
    "    POSITION.append([])\n",
    "for i in range(HEIGHT):\n",
    "    for j in range(WIDTH):\n",
    "        temp_y = label_map[i, j]\n",
    "        if temp_y != 0:\n",
    "            temp_x = patch_data(i, j)\n",
    "            CLASSES[temp_y].append(temp_x)\n",
    "            POSITION[temp_y].append([i,j])\n",
    "for i in range(CLASS_NUM):\n",
    "    print ('CLASS',str(i) + '\\t',len(CLASSES[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "this class is empty\n",
      "1\n",
      "current class data size: (29779, 5, 5, 204)\n",
      "2\n",
      "current class data size: (7590, 5, 5, 204)\n",
      "\n",
      "Total num of Training patches: 37369\n",
      "\n",
      "label class name: [0 1]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATCH, TRAIN_LABELS = [], []\n",
    "# class_name=setting.class_name\n",
    "# for c in class_name:  # for each class\n",
    "for c in range(CLASS_NUM):\n",
    "    print(c)\n",
    "    num=len(CLASSES[c])\n",
    "    if num==0:\n",
    "        print('this class is empty')\n",
    "        continue\n",
    "    randIdx = np.arange(num)\n",
    "    shuffle(randIdx)  # Randomly shuffle patches in the class\n",
    "    current_class_data = np.array(CLASSES[c],dtype = DTYPE)\n",
    "    rand_current_class_data = current_class_data[randIdx,:,:,:]\n",
    "    print('current class data size:', rand_current_class_data.shape)\n",
    "    if c==1:\n",
    "        TRAIN_LABELS.extend(np.full(num, 0, dtype=int))\n",
    "    elif c==2:\n",
    "        TRAIN_LABELS.extend(np.full(num, 1, dtype=int))\n",
    "    TRAIN_PATCH.extend(rand_current_class_data)\n",
    "#     TRAIN_LABELS.extend(np.full(num, c, dtype=int))\n",
    "TRAIN_PATCH = np.array(TRAIN_PATCH, dtype=DTYPE)\n",
    "print ('\\nTotal num of Training patches: %d\\n' % len(TRAIN_PATCH))\n",
    "print('label class name:',np.unique(TRAIN_LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing: ./sample/Train_1_5_5_float64.h5\n",
      "Successfully save training data set!\n"
     ]
    }
   ],
   "source": [
    "# save files\n",
    "# 1. Training data\n",
    "file_name = train_data_name +'_'+ str(PATCH_SIZE) +'_'+ str(DTYPE) +'.h5'\n",
    "print ('Writing: ' + file_name)\n",
    "with h5py.File(file_name, 'w') as file:\n",
    "    file.create_dataset('train_patch', data=TRAIN_PATCH)\n",
    "    file.create_dataset('train_labels', data=TRAIN_LABELS, dtype='i8')\n",
    "print ('Successfully save training data set!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
