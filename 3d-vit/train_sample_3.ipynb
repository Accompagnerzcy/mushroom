{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先按照类别汇总所有训练图片中的标注样本，然后再划分训练集\n",
    "图片序号为20,22,26,28,29，31,38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import scipy.io as scio\n",
    "import os\n",
    "import numpy as np\n",
    "import setting_2 as setting\n",
    "from random import shuffle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATCH_SIZE= 7\n",
      "CLASS_NUM= 2\n",
      "DTYPE: float64\n"
     ]
    }
   ],
   "source": [
    "PATCH_SIZE = setting.PATCH_SIZE\n",
    "print('PATCH_SIZE=',PATCH_SIZE)\n",
    "CLASS_NUM =2\n",
    "print('CLASS_NUM=',CLASS_NUM)\n",
    "DTYPE=setting.DTYPE\n",
    "print('DTYPE:', DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0, class_1=[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no=setting.train_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_patch size: (10523, 7, 7, 204)\n",
      "train_label length: 10523\n"
     ]
    }
   ],
   "source": [
    "# 加载训练样本20\n",
    "train_filename = './sample/Train_'+str(no)+'_20' +'_'+ str(PATCH_SIZE) +'_'+ str(DTYPE) +'.h5'\n",
    "with h5py.File(train_filename,'r') as readfile:\n",
    "    train_patch = readfile['train_patch'][:]\n",
    "    train_labels = readfile['train_labels'][:]    \n",
    "print('train_patch size:',train_patch.shape)\n",
    "print('train_label length:', len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS 0\t 6637\n",
      "CLASS 1\t 3886\n",
      "Class 0 data size: 6637\n",
      "Class 1 data size: 3886\n"
     ]
    }
   ],
   "source": [
    "CLASSES = []\n",
    "for i in range(CLASS_NUM):\n",
    "    CLASSES.append([])\n",
    "for i in range(len(train_labels)):\n",
    "    temp_y = train_labels[i]\n",
    "    temp_x = train_patch[i,:,:,:]\n",
    "    CLASSES[temp_y].append(temp_x)\n",
    "for i in range(CLASS_NUM):\n",
    "    print('CLASS',str(i) + '\\t',len(CLASSES[i]))\n",
    "    \n",
    "class_0.extend(CLASSES[0])\n",
    "class_1.extend(CLASSES[1])\n",
    "print('Class 0 data size:',len(class_0))\n",
    "print('Class 1 data size:',len(class_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_patch size: (13923, 7, 7, 204)\n",
      "train_label length: 13923\n",
      "CLASS 0\t 12171\n",
      "CLASS 1\t 1752\n",
      "Class 0 data size: 18808\n",
      "Class 1 data size: 5638\n"
     ]
    }
   ],
   "source": [
    "# 加载训练样本22\n",
    "train_filename = './sample/Train_'+str(no)+'_22' +'_'+ str(PATCH_SIZE) +'_'+ str(DTYPE) +'.h5'\n",
    "with h5py.File(train_filename,'r') as readfile:\n",
    "    train_patch = readfile['train_patch'][:]\n",
    "    train_labels = readfile['train_labels'][:]    \n",
    "print('train_patch size:',train_patch.shape)\n",
    "print('train_label length:', len(train_labels))\n",
    "\n",
    "\n",
    "CLASSES = []\n",
    "for i in range(CLASS_NUM):\n",
    "    CLASSES.append([])\n",
    "for i in range(len(train_labels)):\n",
    "    temp_y = train_labels[i]\n",
    "    temp_x = train_patch[i,:,:,:]\n",
    "    CLASSES[temp_y].append(temp_x)\n",
    "for i in range(CLASS_NUM):\n",
    "    print('CLASS',str(i) + '\\t',len(CLASSES[i]))\n",
    "\n",
    "class_0.extend(CLASSES[0])\n",
    "class_1.extend(CLASSES[1])\n",
    "print('Class 0 data size:',len(class_0))\n",
    "print('Class 1 data size:',len(class_1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_patch size: (6612, 7, 7, 204)\n",
      "train_label length: 6612\n",
      "CLASS 0\t 3935\n",
      "CLASS 1\t 2677\n",
      "Class 0 data size: 22743\n",
      "Class 1 data size: 8315\n"
     ]
    }
   ],
   "source": [
    "# 加载训练样本26\n",
    "train_filename =  './sample/Train_'+str(no)+'_26' +'_'+ str(PATCH_SIZE) +'_'+ str(DTYPE) +'.h5'\n",
    "with h5py.File(train_filename,'r') as readfile:\n",
    "    train_patch = readfile['train_patch'][:]\n",
    "    train_labels = readfile['train_labels'][:]    \n",
    "print('train_patch size:',train_patch.shape)\n",
    "print('train_label length:', len(train_labels))\n",
    "\n",
    "\n",
    "CLASSES = []\n",
    "for i in range(CLASS_NUM):\n",
    "    CLASSES.append([])\n",
    "for i in range(len(train_labels)):\n",
    "    temp_y = train_labels[i]\n",
    "    temp_x = train_patch[i,:,:,:]\n",
    "    CLASSES[temp_y].append(temp_x)\n",
    "for i in range(CLASS_NUM):\n",
    "    print('CLASS',str(i) + '\\t',len(CLASSES[i]))\n",
    "\n",
    "    \n",
    "class_0.extend(CLASSES[0])\n",
    "class_1.extend(CLASSES[1])\n",
    "print('Class 0 data size:',len(class_0))\n",
    "print('Class 1 data size:',len(class_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_patch size: (10735, 7, 7, 204)\n",
      "train_label length: 10735\n",
      "CLASS 0\t 7438\n",
      "CLASS 1\t 3297\n",
      "Class 0 data size: 30181\n",
      "Class 1 data size: 11612\n"
     ]
    }
   ],
   "source": [
    "# 加载训练样本28\n",
    "train_filename =  './sample/Train_'+str(no)+'_28' +'_'+ str(PATCH_SIZE) +'_'+ str(DTYPE) +'.h5'\n",
    "with h5py.File(train_filename,'r') as readfile:\n",
    "    train_patch = readfile['train_patch'][:]\n",
    "    train_labels = readfile['train_labels'][:]    \n",
    "print('train_patch size:',train_patch.shape)\n",
    "print('train_label length:', len(train_labels))\n",
    "\n",
    "\n",
    "CLASSES = []\n",
    "for i in range(CLASS_NUM):\n",
    "    CLASSES.append([])\n",
    "for i in range(len(train_labels)):\n",
    "    temp_y = train_labels[i]\n",
    "    temp_x = train_patch[i,:,:,:]\n",
    "    CLASSES[temp_y].append(temp_x)\n",
    "for i in range(CLASS_NUM):\n",
    "    print('CLASS',str(i) + '\\t',len(CLASSES[i]))\n",
    "\n",
    "    \n",
    "class_0.extend(CLASSES[0])\n",
    "class_1.extend(CLASSES[1])\n",
    "print('Class 0 data size:',len(class_0))\n",
    "print('Class 1 data size:',len(class_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_patch size: (11244, 7, 7, 204)\n",
      "train_label length: 11244\n",
      "CLASS 0\t 9989\n",
      "CLASS 1\t 1255\n",
      "Class 0 data size: 40170\n",
      "Class 1 data size: 12867\n"
     ]
    }
   ],
   "source": [
    "# 加载训练样本29\n",
    "train_filename = './sample/Train_'+str(no)+'_29' +'_'+ str(PATCH_SIZE) +'_'+ str(DTYPE) +'.h5'\n",
    "with h5py.File(train_filename,'r') as readfile:\n",
    "    train_patch = readfile['train_patch'][:]\n",
    "    train_labels = readfile['train_labels'][:]    \n",
    "print('train_patch size:',train_patch.shape)\n",
    "print('train_label length:', len(train_labels))\n",
    "\n",
    "\n",
    "CLASSES = []\n",
    "for i in range(CLASS_NUM):\n",
    "    CLASSES.append([])\n",
    "for i in range(len(train_labels)):\n",
    "    temp_y = train_labels[i]\n",
    "    temp_x = train_patch[i,:,:,:]\n",
    "    CLASSES[temp_y].append(temp_x)\n",
    "for i in range(CLASS_NUM):\n",
    "    print('CLASS',str(i) + '\\t',len(CLASSES[i]))\n",
    "\n",
    "    \n",
    "class_0.extend(CLASSES[0])\n",
    "class_1.extend(CLASSES[1])\n",
    "print('Class 0 data size:',len(class_0))\n",
    "print('Class 1 data size:',len(class_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_patch size: (7990, 7, 7, 204)\n",
      "train_label length: 7990\n",
      "CLASS 0\t 3659\n",
      "CLASS 1\t 4331\n",
      "Class 0 data size: 43829\n",
      "Class 1 data size: 17198\n"
     ]
    }
   ],
   "source": [
    "# 加载训练样本31\n",
    "train_filename = './sample/Train_'+str(no)+'_31' +'_'+ str(PATCH_SIZE) +'_'+ str(DTYPE) +'.h5'\n",
    "with h5py.File(train_filename,'r') as readfile:\n",
    "    train_patch = readfile['train_patch'][:]\n",
    "    train_labels = readfile['train_labels'][:]    \n",
    "print('train_patch size:',train_patch.shape)\n",
    "print('train_label length:', len(train_labels))\n",
    "\n",
    "\n",
    "CLASSES = []\n",
    "for i in range(CLASS_NUM):\n",
    "    CLASSES.append([])\n",
    "for i in range(len(train_labels)):\n",
    "    temp_y = train_labels[i]\n",
    "    temp_x = train_patch[i,:,:,:]\n",
    "    CLASSES[temp_y].append(temp_x)\n",
    "for i in range(CLASS_NUM):\n",
    "    print('CLASS',str(i) + '\\t',len(CLASSES[i]))\n",
    "\n",
    "    \n",
    "class_0.extend(CLASSES[0])\n",
    "class_1.extend(CLASSES[1])\n",
    "print('Class 0 data size:',len(class_0))\n",
    "print('Class 1 data size:',len(class_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_patch size: (2598, 7, 7, 204)\n",
      "train_label length: 2598\n",
      "CLASS 0\t 1357\n",
      "CLASS 1\t 1241\n",
      "Class 0 data size: 45186\n",
      "Class 1 data size: 18439\n"
     ]
    }
   ],
   "source": [
    "# 加载训练样本38\n",
    "train_filename = './sample/Train_'+str(no)+'_38' +'_'+ str(PATCH_SIZE) +'_'+ str(DTYPE) +'.h5'\n",
    "with h5py.File(train_filename,'r') as readfile:\n",
    "    train_patch = readfile['train_patch'][:]\n",
    "    train_labels = readfile['train_labels'][:]    \n",
    "print('train_patch size:',train_patch.shape)\n",
    "print('train_label length:', len(train_labels))\n",
    "\n",
    "\n",
    "CLASSES = []\n",
    "for i in range(CLASS_NUM):\n",
    "    CLASSES.append([])\n",
    "for i in range(len(train_labels)):\n",
    "    temp_y = train_labels[i]\n",
    "    temp_x = train_patch[i,:,:,:]\n",
    "    CLASSES[temp_y].append(temp_x)\n",
    "for i in range(CLASS_NUM):\n",
    "    print('CLASS',str(i) + '\\t',len(CLASSES[i]))\n",
    "\n",
    "class_0.extend(CLASSES[0])\n",
    "class_1.extend(CLASSES[1])\n",
    "print('Class 0 data size:',len(class_0))\n",
    "print('Class 1 data size:',len(class_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATCH, TRAIN_LABEL = [], []\n",
    "VAL_PATCH, VAL_LABEL =[], []\n",
    "# class_name=setting.class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "current class data size: (45186, 7, 7, 204)\n",
      "1\n",
      "current class data size: (18439, 7, 7, 204)\n",
      "train data size: 20000\n",
      "train label size: 20000\n",
      "TRAIN_PATCH shape: (20000, 7, 7, 204)\n"
     ]
    }
   ],
   "source": [
    "for c in range(CLASS_NUM):  # for each class\n",
    "    print(c)\n",
    "    if len(CLASSES[c])==0:\n",
    "        print('this class is empty')\n",
    "        continue\n",
    "    if c==0:\n",
    "        randIdx = np.arange(len(class_0))\n",
    "        shuffle(randIdx)  # Randomly shuffle patches in the class\n",
    "        current_class_data = np.array(class_0,dtype = DTYPE)\n",
    "        rand_current_class_data = current_class_data[randIdx,:,:,:]\n",
    "        print('current class data size:', rand_current_class_data.shape)    \n",
    "        train_split_size=10000\n",
    "        TRAIN_PATCH.extend(rand_current_class_data[:train_split_size])\n",
    "        TRAIN_LABEL.extend(np.full(train_split_size, c, dtype=int))\n",
    "    if c==1:\n",
    "        randIdx = np.arange(len(class_1))\n",
    "        shuffle(randIdx)  # Randomly shuffle patches in the class\n",
    "        current_class_data = np.array(class_1,dtype = DTYPE)\n",
    "        rand_current_class_data = current_class_data[randIdx,:,:,:]\n",
    "        print('current class data size:', rand_current_class_data.shape)    \n",
    "        train_split_size=10000\n",
    "        TRAIN_PATCH.extend(rand_current_class_data[:train_split_size])\n",
    "        TRAIN_LABEL.extend(np.full(train_split_size, c, dtype=int))\n",
    "\n",
    "print('train data size:',len(TRAIN_PATCH))\n",
    "print('train label size:',len(TRAIN_LABEL))\n",
    "\n",
    "TRAIN_PATCH = np.array(TRAIN_PATCH, dtype=DTYPE)\n",
    "print('TRAIN_PATCH shape:',TRAIN_PATCH.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing: ./sample/TrainSet_5_10000_7_float64.h5\n",
      "Successfully save training data set!\n"
     ]
    }
   ],
   "source": [
    "# save files\n",
    "# 1. Training data\n",
    "file_name = setting.train_data_name +'_'+ str(PATCH_SIZE) +'_'+ str(DTYPE) +'.h5'\n",
    "print ('Writing: ' + file_name)\n",
    "with h5py.File(file_name, 'w') as file:\n",
    "    file.create_dataset('train_patch', data=TRAIN_PATCH)\n",
    "    file.create_dataset('train_labels', data=TRAIN_LABEL, dtype='i8')\n",
    "print ('Successfully save training data set!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env-torch] *",
   "language": "python",
   "name": "conda-env-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
