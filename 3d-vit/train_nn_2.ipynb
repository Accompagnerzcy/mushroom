{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import numpy as np\n",
    "import setting_2 as setting\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import ComFunction as cf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.backends.cudnn as cudnn\n",
    "# from scipy.io import loadmat\n",
    "# from scipy.io import savemat\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "from vit_pytorch import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type=='cuda':\n",
    "#     dtype = torch.float32\n",
    "#     torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "    dtype = torch.float64\n",
    "    torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "else:\n",
    "#     dtype = torch.float32\n",
    "#     torch.set_default_tensor_type(torch.FloatTensor)\n",
    "    dtype = torch.float64\n",
    "    torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "print(device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperData(Dataset):\n",
    "    def __init__(self, data, labels, transfor):\n",
    "        self.data = data\n",
    "        self.transformer = transfor\n",
    "        self.labels = labels\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index,:,:]\n",
    "        label = self.labels[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __labels__(self):\n",
    "        return self.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_neighborhood_band(x_train, band, band_patch, patch=5):\n",
    "    nn = band_patch // 2\n",
    "    pp = (patch*patch) // 2\n",
    "    x_train_reshape = x_train.reshape(x_train.shape[0], patch*patch, band)\n",
    "    x_train_band = np.zeros((x_train.shape[0], patch*patch*band_patch, band),dtype=float)\n",
    "    # 中心区域\n",
    "    x_train_band[:,nn*patch*patch:(nn+1)*patch*patch,:] = x_train_reshape\n",
    "    #左边镜像\n",
    "    for i in range(nn):\n",
    "        if pp > 0:\n",
    "            x_train_band[:,i*patch*patch:(i+1)*patch*patch,:i+1] = x_train_reshape[:,:,band-i-1:]\n",
    "            x_train_band[:,i*patch*patch:(i+1)*patch*patch,i+1:] = x_train_reshape[:,:,:band-i-1]\n",
    "        else:\n",
    "            x_train_band[:,i:(i+1),:(nn-i)] = x_train_reshape[:,0:1,(band-nn+i):]\n",
    "            x_train_band[:,i:(i+1),(nn-i):] = x_train_reshape[:,0:1,:(band-nn+i)]\n",
    "    #右边镜像\n",
    "    for i in range(nn):\n",
    "        if pp > 0:\n",
    "            x_train_band[:,(nn+i+1)*patch*patch:(nn+i+2)*patch*patch,:band-i-1] = x_train_reshape[:,:,i+1:]\n",
    "            x_train_band[:,(nn+i+1)*patch*patch:(nn+i+2)*patch*patch,band-i-1:] = x_train_reshape[:,:,:i+1]\n",
    "        else:\n",
    "            x_train_band[:,(nn+1+i):(nn+2+i),(band-i-1):] = x_train_reshape[:,0:1,:(i+1)]\n",
    "            x_train_band[:,(nn+1+i):(nn+2+i),:(band-i-1)] = x_train_reshape[:,0:1,(i+1):]\n",
    "    return x_train_band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH=setting.EPOCH\n",
    "BATCH_SIZE=setting.BATCH_SIZE\n",
    "LR=setting.LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (14000, 7, 7, 204)\n",
      "train label name: [0 1]\n",
      "3.2608695030212402\n",
      "0.06606606394052505\n",
      "train max: 3.2608695030212402\n"
     ]
    }
   ],
   "source": [
    "train_filename =setting.train_data_name +'_'+ str(setting.PATCH_SIZE) + '_'+ str(setting.DTYPE) +'.h5'\n",
    "with h5py.File(train_filename,'r') as readfile:\n",
    "    train=readfile['train_patch'][:]\n",
    "    train_labels=readfile['train_labels'][:]\n",
    "print('train size:', train.shape)\n",
    "print('train label name:',np.unique(train_labels))\n",
    "print(np.max(train))\n",
    "print(np.min(train))\n",
    "\n",
    "train_max=np.max(np.abs(train))\n",
    "print('train max:',train_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 343, 204)\n",
      "(14000, 204, 343)\n"
     ]
    }
   ],
   "source": [
    "train_band = gain_neighborhood_band(train, setting.band, setting.band_patches, setting.PATCH_SIZE)\n",
    "print(train_band.shape)\n",
    "train_band =train_band.transpose(0,2,1)\n",
    "print(train_band .shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val size: (7000, 7, 7, 204)\n",
      "val label name: [0 1]\n",
      "1.2545454502105713\n",
      "0.04953031614422798\n",
      "val max: 1.2545454502105713\n",
      "(7000, 343, 204)\n",
      "(7000, 204, 343)\n"
     ]
    }
   ],
   "source": [
    "val_filename = setting.val_data_name +'_'+ str(setting.PATCH_SIZE) +'_'+ str(setting.DTYPE) +'.h5'\n",
    "with h5py.File(val_filename,'r') as readfile:\n",
    "    val=readfile['val_patch'][:]\n",
    "    val_labels=readfile['val_labels'][:]\n",
    "print('val size:', val.shape)\n",
    "print('val label name:',np.unique(val_labels))\n",
    "print(np.max(val))\n",
    "print(np.min(val))\n",
    "\n",
    "val_max=np.max(np.abs(val))\n",
    "print('val max:',val_max)\n",
    "\n",
    "\n",
    "val_band = gain_neighborhood_band(val, setting.band, setting.band_patches, setting.PATCH_SIZE)\n",
    "print(val_band.shape)\n",
    "val_band =val_band.transpose(0,2,1)\n",
    "print(val_band.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpu\n",
    "# train_set=HyperData(train_band,train_labels, None)\n",
    "# trainloader= Data.DataLoader(dataset=train_set,batch_size=BATCH_SIZE,shuffle=True, num_workers=0)\n",
    "\n",
    "# val_set=HyperData(val_band, val_labels, None)\n",
    "# valloader= Data.DataLoader(dataset=val_set,batch_size=BATCH_SIZE,shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gpu\n",
    "train_set=HyperData(train_band,train_labels, None)\n",
    "trainloader= Data.DataLoader(dataset=train_set,batch_size=BATCH_SIZE,shuffle=True, num_workers=0,generator=torch.Generator(device='cuda'))\n",
    "\n",
    "val_set=HyperData(val_band, val_labels, None)\n",
    "valloader= Data.DataLoader(dataset=val_set,batch_size=BATCH_SIZE,shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs\\nn_2023_01_16_10_43\n"
     ]
    }
   ],
   "source": [
    "time_str=time.strftime(\"%Y_%m_%d_%H_%M\", time.localtime())\n",
    "\n",
    "writer_name=os.path.join(setting.writer_name,'nn_'+time_str)\n",
    "print(writer_name)\n",
    "writer = SummaryWriter(writer_name)\n",
    "# tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=ViT(\n",
    "    image_size = setting.PATCH_SIZE,\n",
    "    near_band = setting.band_patches,\n",
    "    num_patches = setting.band,\n",
    "    num_classes = setting.num_class,\n",
    "    dim = 64,\n",
    "    depth =2,\n",
    "    heads = 4,\n",
    "    mlp_dim =6,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1,\n",
    "    mode = setting.mode\n",
    ").to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=setting.LR, weight_decay=setting.weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=setting.EPOCH//10, gamma=setting.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc=0\n",
    "best_epoch=0\n",
    "\n",
    "global_steps=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\ViT_train_result\\traintime_2023_01_16_10_43.txt\n",
      "epoch: 0\n",
      "global steps   200 running loss: 0.590\n",
      "train oa: 66.75 train loss 0.5624863202559458\n",
      " val oa: 0.8544285714285714 val_loss: 0.38154877831289297\n",
      "epoch: 0 best val accuracy: 0.8544285714285714\n",
      "epoch: 1\n",
      "global steps   400 running loss: 0.213\n",
      "train oa: 90.66428571428571 train loss 0.23109978807442813\n",
      " val oa: 0.8962857142857142 val_loss: 0.26265342898832006\n",
      "epoch: 1 best val accuracy: 0.8962857142857142\n",
      "epoch: 2\n",
      "global steps   600 running loss: 0.156\n",
      "train oa: 92.1 train loss 0.19160443793728132\n",
      " val oa: 0.8922857142857142 val_loss: 0.2620066463661791\n",
      "epoch: 3\n",
      "global steps   800 running loss: 0.135\n",
      "train oa: 92.60714285714286 train loss 0.18070028070042984\n",
      " val oa: 0.8997142857142857 val_loss: 0.25448680380171496\n",
      "epoch: 3 best val accuracy: 0.8997142857142857\n",
      "epoch: 4\n",
      "global steps  1000 running loss: 0.114\n",
      "train oa: 92.88571428571429 train loss 0.17790197074349598\n",
      " val oa: 0.8977142857142857 val_loss: 0.255058312255156\n",
      "epoch: 5\n",
      "global steps  1200 running loss: 0.084\n",
      "train oa: 93.25714285714285 train loss 0.16398977038351434\n",
      " val oa: 0.768 val_loss: 0.5448348004748049\n",
      "epoch: 6\n",
      "global steps  1400 running loss: 0.067\n",
      "train oa: 93.78571428571429 train loss 0.15153700430117664\n",
      " val oa: 0.8468571428571429 val_loss: 0.3782515469500721\n",
      "epoch: 7\n",
      "global steps  1600 running loss: 0.055\n",
      "train oa: 94.00714285714285 train loss 0.14705066197477995\n",
      " val oa: 0.8268571428571428 val_loss: 0.4434374893902427\n",
      "epoch: 8\n",
      "global steps  1800 running loss: 0.036\n",
      "train oa: 94.47857142857143 train loss 0.14038149472402675\n",
      " val oa: 0.8761428571428571 val_loss: 0.2980433701021936\n",
      "epoch: 9\n",
      "global steps  2000 running loss: 0.020\n",
      "train oa: 94.29285714285714 train loss 0.14478049617438724\n",
      " val oa: 0.8975714285714286 val_loss: 0.2665574386340556\n",
      "epoch: 10\n",
      "global steps  2200 running loss: 0.007\n",
      "global steps  2400 running loss: 0.136\n",
      "train oa: 94.65 train loss 0.13589113099631062\n",
      " val oa: 0.8914285714285715 val_loss: 0.25521004107515494\n",
      "epoch: 11\n",
      "global steps  2600 running loss: 0.122\n",
      "train oa: 94.80714285714286 train loss 0.1301115695827855\n",
      " val oa: 0.9058571428571428 val_loss: 0.2364501914439256\n",
      "epoch: 11 best val accuracy: 0.9058571428571428\n",
      "epoch: 12\n",
      "global steps  2800 running loss: 0.110\n",
      "train oa: 94.6 train loss 0.1312324863464675\n",
      " val oa: 0.9128571428571428 val_loss: 0.2366940423522301\n",
      "epoch: 12 best val accuracy: 0.9128571428571428\n",
      "epoch: 13\n",
      "global steps  3000 running loss: 0.089\n",
      "train oa: 95.32857142857142 train loss 0.11908348196723743\n",
      " val oa: 0.8848571428571429 val_loss: 0.28179378445124703\n",
      "epoch: 14\n",
      "global steps  3200 running loss: 0.081\n",
      "train oa: 94.97857142857143 train loss 0.12096558442853012\n",
      " val oa: 0.9 val_loss: 0.25420300052941075\n",
      "epoch: 15\n",
      "global steps  3400 running loss: 0.073\n",
      "train oa: 95.22857142857143 train loss 0.12176051670343355\n",
      " val oa: 0.8781428571428571 val_loss: 0.28755619678153227\n",
      "epoch: 16\n",
      "global steps  3600 running loss: 0.051\n",
      "train oa: 95.51428571428572 train loss 0.11229847965209216\n",
      " val oa: 0.904 val_loss: 0.2493326970522271\n",
      "epoch: 17\n",
      "global steps  3800 running loss: 0.047\n",
      "train oa: 95.16428571428571 train loss 0.11926816081224678\n",
      " val oa: 0.8361428571428572 val_loss: 0.36031765585022824\n",
      "epoch: 18\n",
      "global steps  4000 running loss: 0.036\n",
      "train oa: 95.62857142857143 train loss 0.10778868900933182\n",
      " val oa: 0.8812857142857143 val_loss: 0.2907758868424394\n",
      "epoch: 19\n",
      "global steps  4200 running loss: 0.020\n",
      "train oa: 95.36428571428571 train loss 0.11436255769719737\n",
      " val oa: 0.8968571428571429 val_loss: 0.25446582228142445\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "filename=os.path.join(setting.train_result_dir,'traintime_'+time_str+'.txt')\n",
    "print(filename)\n",
    "\n",
    "result=open(filename,'a')\n",
    "start=time.time()\n",
    "for epoch in range(setting.EPOCH):  # loop over the dataset multiple times\n",
    "    print('epoch:',epoch)\n",
    "    result.write('epoch:'+str(epoch)+'\\n')\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    train_loss= 0.0\n",
    "    net.train()\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        b_inputs=Variable(inputs).to(device)\n",
    "        b_labels=Variable(labels).to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "#         print(inputs.shape)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(b_inputs)\n",
    "#         print(labels.unique)\n",
    "#         print(outputs.unique)\n",
    "        loss = criterion(outputs, b_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        global_steps+=1\n",
    "#         loss_list.append(loss)\n",
    "            \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        train_loss += loss.item()\n",
    "        if (global_steps) % 200 == 0:    # print every 2000 mini-batches\n",
    "            print('global steps %5d running loss: %.3f' %\n",
    "                  (global_steps, running_loss / 200))\n",
    "#             state = {\n",
    "#                 'epoch': epoch,\n",
    "#                 'step': i,\n",
    "#                 'net': net.state_dict(),\n",
    "#                 'optimizer':optimizer.state_dict(),\n",
    "#                 'loss':running_loss / 200\n",
    "#             }\n",
    "#             checkpoint_name=os.path.join(setting.checkpoint_dir,'model_time_'+time_str+'_epoch_'+str(epoch)+'_step_'+str(i)+'.pth')\n",
    "#             torch.save(state, checkpoint_name)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        #save loss log file\n",
    "#         if global_steps%10 ==0:\n",
    "#             writer.add_scalar('train_loss',loss,global_steps)\n",
    "            \n",
    "        \n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print( 'train oa:', 100 * correct / total,'train loss',train_loss/len(trainloader))\n",
    "    result.write('train accuracy:'+str(100 * correct / total) +'\\t'+'train loss:'+str(train_loss/len(trainloader)))\n",
    "    #save training accuracy log file\n",
    "    writer.add_scalar('train_accuracy',accuracy,epoch)\n",
    "    writer.add_scalar('train_loss',train_loss/len(trainloader),epoch)\n",
    "    \n",
    "    \n",
    "    val_correct = 0.0\n",
    "    val_total = 0.0\n",
    "    val_loss = 0.0\n",
    "    net.eval()\n",
    "    for valdata in valloader:\n",
    "        val_inputs, val_labels = valdata\n",
    "        val_inputs = val_inputs.to(device)\n",
    "        val_labels =  val_labels.to(device)\n",
    "        val_outputs = net(val_inputs)\n",
    "        valloss = criterion(val_outputs, val_labels)\n",
    "        val_loss += valloss.item()\n",
    "        _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "        val_total += val_labels.size(0)\n",
    "        val_correct += (val_predicted == val_labels).sum().item()\n",
    "    val_oa=val_correct/val_total\n",
    "    print(' val oa:',val_oa, 'val_loss:',val_loss/len(valloader))\n",
    "    result.write('\\t val oa:'+str(val_oa)+'\\t'+ 'val_loss:'+str(val_loss/len(valloader)))\n",
    "    writer.add_scalar('val_Accu',val_oa , epoch)\n",
    "    writer.add_scalar('val_loss',val_loss/len(valloader) , epoch)\n",
    "    \n",
    "    if val_oa > best_acc:\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'accuracy': val_oa,\n",
    "            'net': net.state_dict(),\n",
    "            'optimizer':optimizer.state_dict(),\n",
    "            'loss':loss\n",
    "        }\n",
    "        best_model_name=os.path.join(setting.best_model_dir,'model_time_'+time_str+'.pth')\n",
    "        torch.save(state, best_model_name)\n",
    "        best_acc=val_oa\n",
    "        best_epoch=epoch\n",
    "        print('epoch:',epoch,'best val accuracy:',val_oa)\n",
    "    \n",
    "    #pridict  testing data and save accuracy log file\n",
    "#     if (epoch) % 10 == 0:\n",
    "#         test_correct = 0.0\n",
    "#         test_total = 0.0\n",
    "#         test_loss = 0.0\n",
    "#         net.eval()\n",
    "#         for testdata in testloader:\n",
    "#             test_inputs, test_labels = testdata\n",
    "#             test_inputs = test_inputs.to(device)\n",
    "#             test_labels =  test_labels.to(device)\n",
    "#             test_outputs = net(test_inputs)\n",
    "#             tsloss = criterion(test_outputs, test_labels)\n",
    "#             test_loss += tsloss.item()\n",
    "#             _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "#             test_total += test_labels.size(0)\n",
    "#             test_correct += (test_predicted == test_labels).sum().item()\n",
    "#         oa=test_correct/test_total\n",
    "#         print(' test oa:',oa, 'loss:',test_loss/len(testloader))\n",
    "#         result.write('\\t test oa:'+str(oa)+'\\t'+ 'loss:'+str(test_loss/len(testloader)))\n",
    "#         writer.add_scalar('Test_Accu',oa , epoch)\n",
    "#         writer.add_scalar('Test_loss',test_loss/len(testloader) , epoch)\n",
    "    \n",
    "#         if oa > best_acc:\n",
    "#             state = {\n",
    "#                 'epoch': epoch,\n",
    "#                 'accuracy': oa,\n",
    "#                 'net': net.state_dict(),\n",
    "#                 'optimizer':optimizer.state_dict(),\n",
    "#                 'loss':loss\n",
    "#             }\n",
    "#             best_model_name=os.path.join(setting.best_model_dir,'model_time_'+time_str+'.pth')\n",
    "#             torch.save(state, best_model_name)\n",
    "#             best_acc=oa\n",
    "#             print('epoch:',epoch,'best test accuracy:',oa)\n",
    "        \n",
    "\n",
    "    finish_state = {\n",
    "        'epoch': epoch,\n",
    "        'net': net.state_dict(),\n",
    "        'optimizer':optimizer.state_dict(),\n",
    "        'loss':loss,\n",
    "        'train_oa':accuracy,\n",
    "#         'test_oa':oa\n",
    "        }\n",
    "end=time.time()\n",
    "model_name=os.path.join(setting.model_dir,'model_time_'+time_str+'.pth')\n",
    "torch.save(finish_state, model_name)\n",
    "#plt.ioff()\n",
    "#plt.show()\n",
    "print('Finished Training')\n",
    "writer.close()\n",
    "result.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_acc: 0.9128571428571428\n",
      "best_epoch: 12\n",
      "train time: 576.1477062702179\n",
      ".\\model\\model_best\\model_time_2023_01_16_10_43.pth\n",
      ".\\model\\model_time_2023_01_16_10_43.pth\n"
     ]
    }
   ],
   "source": [
    "print('best_acc:',best_acc)\n",
    "print('best_epoch:',best_epoch)\n",
    "print('train time:', end-start)\n",
    "print(best_model_name)\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model_name='./model/salinas/model_best/model_time_2021_03_18_12_17.pth'\n",
    "# model_name='.\\model\\salinas\\model_time_2020_03_31_11_43.pth'\n",
    "# model = torch.load(model_name)\n",
    "model = torch.load(best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(model['net'])\n",
    "# optimizer.load_state_dict(model['optimizer'])\n",
    "# start_epoch = model['epoch'] + 1\n",
    "# loss=model['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h'p\\AppData\\Local\\Temp\\ipykernel_13612\\1710881646.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  _, trpredicted = torch.max(F.softmax(troutputs), 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict training set finished\n",
      "predict train time: 9.871007442474365\n",
      "OA_train: 0.965 \n",
      "AA_train: 0.965 \n",
      "kappa_train: 0.9299999999999999 \n",
      "acc_train: [0.95385714 0.97614286]\n"
     ]
    }
   ],
   "source": [
    "predict_trainlabels=[]\n",
    "trainlabels=[]\n",
    "t1=time.time()\n",
    "with torch.no_grad():\n",
    "    for trdata in trainloader:\n",
    "        trinputs, trlabels = trdata\n",
    "        trinputs = trinputs.to(device)\n",
    "        trlabels = trlabels.to(device)\n",
    "        troutputs = net(trinputs)\n",
    "        _, trpredicted = torch.max(F.softmax(troutputs), 1)\n",
    "        predict_trainlabels.extend(trpredicted)\n",
    "        trainlabels.extend(trlabels)\n",
    "    print('predict training set finished')\n",
    "#print(len(trainlabels))\n",
    "#print(len(predict_trainlabels))\n",
    "t2=time.time()\n",
    "print('predict train time:',t2-t1)\n",
    "\n",
    "predict_trainlabels=torch.tensor(predict_trainlabels, device='cpu')\n",
    "trainlabels=torch.tensor(trainlabels,device='cpu')\n",
    "\n",
    "oa_train, aa_train, kappa_train, acc_train=cf.eval_results_own(predict_trainlabels,trainlabels,2)\n",
    "print('OA_train:',oa_train, '\\nAA_train:', aa_train, '\\nkappa_train:', kappa_train, '\\nacc_train:', acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h'p\\AppData\\Local\\Temp\\ipykernel_13612\\3946737779.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  _, vpredicted = torch.max(F.softmax(voutputs), 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict val set finished\n",
      "predict val time: 4.927295207977295\n",
      "OA_val: 0.9128571428571428 \n",
      "AA_val: 0.9128571428571428 \n",
      "kappa_val: 0.8257142857142856 \n",
      "acc_val: [0.94542857 0.88028571]\n"
     ]
    }
   ],
   "source": [
    "predict_vallabels=[]\n",
    "val_labels=[]\n",
    "t1=time.time()\n",
    "with torch.no_grad():\n",
    "    for valdata in valloader:\n",
    "        vinputs, vlabels = valdata\n",
    "        vinputs = vinputs.to(device)\n",
    "        vlabels = vlabels.to(device)\n",
    "        voutputs = net(vinputs)\n",
    "        _, vpredicted = torch.max(F.softmax(voutputs), 1)\n",
    "        predict_vallabels.extend(vpredicted)\n",
    "        val_labels.extend(vlabels)\n",
    "    print('predict val set finished')\n",
    "#print(len(trainlabels))\n",
    "#print(len(predict_trainlabels))\n",
    "t2=time.time()\n",
    "print('predict val time:',t2-t1)\n",
    "\n",
    "predict_vallabels=torch.tensor(predict_vallabels, device='cpu')\n",
    "val_labels=torch.tensor(val_labels,device='cpu')\n",
    "\n",
    "oa_val, aa_val, kappa_val, acc_val=cf.eval_results_own(predict_vallabels,val_labels,2)\n",
    "print('OA_val:',oa_val, '\\nAA_val:', aa_val, '\\nkappa_val:', kappa_val, '\\nacc_val:', acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env-torch] *",
   "language": "python",
   "name": "conda-env-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
